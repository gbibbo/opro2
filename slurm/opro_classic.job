#!/bin/bash
#SBATCH --job-name=opro_classic
#SBATCH --partition=3090
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=8
#SBATCH --mem=48G
#SBATCH --time=71:59:00
#SBATCH --output=logs/opro_classic_%j.out
#SBATCH --error=logs/opro_classic_%j.err

# ==============================================================================
# OPRO Classic: Prompt Optimization with Local LLM
# ==============================================================================
#
# This job runs the complete OPRO Classic optimization pipeline:
# - Uses local LLM (Qwen2.5-7B-Instruct) to generate prompts
# - Evaluates with Qwen2-Audio-7B-Instruct (base or LoRA)
# - Optimizes composite reward: R = BA_clip + 0.25·BA_cond (NO length penalty)
# - Tracks 4 psychoacoustic metrics: duration, SNR, filter, reverb
#
# Usage:
#   sbatch slurm/opro_classic.job [base|lora] [seed]
#
# Examples:
#   sbatch slurm/opro_classic.job base 42
#   sbatch slurm/opro_classic.job lora 123
#
# ==============================================================================

set -e
set -u

# Parse arguments
MODE=${1:-base}
SEED=${2:-42}

echo "============================================"
echo "OPRO CLASSIC - SLURM JOB"
echo "============================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_NODELIST"
echo "Mode: $MODE"
echo "Seed: $SEED"
echo "Start time: $(date)"
echo "============================================"

# Create logs directory
mkdir -p logs

# Setup environment (adjust paths for your cluster)
export HF_HOME="/mnt/fast/nobackup/users/$USER/.cache/huggingface"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HF_HUB_CACHE="$HF_HOME/hub"
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
mkdir -p "$HF_HOME" "$TRANSFORMERS_CACHE" "$HF_HUB_CACHE"

# Activate conda environment
# Note: Adjust this line if you use a different conda setup
source ~/miniconda3/etc/profile.d/conda.sh 2>/dev/null || source ~/.bashrc
conda activate opro || conda activate qwen_audio || { echo "ERROR: Could not activate conda environment"; exit 1; }
echo "Conda environment: $CONDA_DEFAULT_ENV"

# Ensure bitsandbytes is installed (required for 4-bit quantization)
echo ""
echo "Checking dependencies..."
if ! python -c "import bitsandbytes" 2>/dev/null; then
    echo "Installing bitsandbytes..."
    pip install bitsandbytes --no-cache-dir
else
    echo "✓ bitsandbytes already installed"
fi

# Verify GPU
echo ""
echo "GPU Information:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv
echo ""

# Configuration
MANIFEST="data/processed/experimental_variants/dev_metadata.csv"
SPLIT="dev"
OPTIMIZER_LLM="Qwen/Qwen2.5-7B-Instruct"
NUM_ITERATIONS=10
CANDIDATES_PER_ITER=6
EARLY_STOPPING=5

# Sampling configuration (for faster iterations)
# Set to 0 to use full dataset (3456 samples), or use subset for smoke tests:
#   - 200-400: quick smoke test (30-60 min/iteration)
#   - 600-800: medium validation
#   - 0: full dev set (slow but complete)
MAX_EVAL_SAMPLES=400
SAMPLE_STRATEGY="stratified"  # uniform, stratified, per_condition
PER_CONDITION_K=5

# Create symlink for path compatibility (some paths may start with "processed/")
ln -sfn "$(pwd)/data/processed" processed

# Verify manifest exists
if [ ! -f "$MANIFEST" ]; then
    echo "ERROR: Manifest not found: $MANIFEST"
    exit 1
fi

echo "Verifying audio paths..."
python - <<'PY'
import pandas as pd
import os
import sys

manifest = "data/processed/experimental_variants/dev_metadata.csv"
if not os.path.exists(manifest):
    print(f"ERROR: Manifest not found: {manifest}")
    sys.exit(1)

df = pd.read_csv(manifest)
print(f"Loaded {len(df)} samples from manifest")

def resolve_path(p):
    p_str = str(p).replace("\\", "/")
    if os.path.isabs(p_str) and os.path.isfile(p_str):
        return p_str
    if os.path.isfile(p_str):
        return p_str
    if p_str.startswith("processed/"):
        candidate = os.path.join("data", p_str)
        if os.path.isfile(candidate):
            return candidate
    candidate = os.path.join(os.getcwd(), p_str)
    if os.path.isfile(candidate):
        return candidate
    return None

df["resolved"] = df["audio_path"].map(resolve_path)
ok_ratio = df["resolved"].notna().mean()

print(f"Files found: {ok_ratio:.1%} ({df['resolved'].notna().sum()}/{len(df)})")

if ok_ratio < 0.95:
    print(f"\nERROR: Only {ok_ratio:.1%} of audio files found!")
    print("Missing files (first 5):")
    for p in df[df["resolved"].isna()]["audio_path"].head(5):
        print(f"  - {p}")
    sys.exit(1)

print("✓ Audio path verification passed")
PY

if [ $? -ne 0 ]; then
    echo "Audio path verification failed. Aborting."
    exit 1
fi

echo ""

# Output directory
if [ "$MODE" == "base" ]; then
    OUTPUT_DIR="results/opro_classic_base_seed${SEED}"
    CHECKPOINT_ARG="--no_lora"
elif [ "$MODE" == "lora" ]; then
    CHECKPOINT="checkpoints/qwen_lora_seed${SEED}/final"
    OUTPUT_DIR="results/opro_classic_lora_seed${SEED}"

    if [ ! -d "$CHECKPOINT" ]; then
        echo "ERROR: Checkpoint not found: $CHECKPOINT"
        echo "Please train a LoRA checkpoint first or use 'base' mode."
        exit 1
    fi

    CHECKPOINT_ARG="--checkpoint $CHECKPOINT"
else
    echo "ERROR: Invalid mode: $MODE"
    echo "Usage: sbatch slurm/opro_classic.job [base|lora] [seed]"
    exit 1
fi

mkdir -p "$OUTPUT_DIR"

echo "Configuration:"
echo "  Manifest: $MANIFEST"
echo "  Split: $SPLIT"
echo "  Optimizer LLM: $OPTIMIZER_LLM"
echo "  Iterations: $NUM_ITERATIONS"
echo "  Candidates/iter: $CANDIDATES_PER_ITER"
echo "  Early stopping: $EARLY_STOPPING"
echo "  Max eval samples: $MAX_EVAL_SAMPLES (0=all, strategy=$SAMPLE_STRATEGY)"
echo "  Output: $OUTPUT_DIR"
echo "  Checkpoint: $CHECKPOINT_ARG"
echo ""

# Save job info
cat > "$OUTPUT_DIR/job_info.txt" <<EOF
Job ID: $SLURM_JOB_ID
Node: $SLURM_NODELIST
Mode: $MODE
Seed: $SEED
Start time: $(date)
Manifest: $MANIFEST
Split: $SPLIT
Optimizer LLM: $OPTIMIZER_LLM
Iterations: $NUM_ITERATIONS
Candidates/iter: $CANDIDATES_PER_ITER
Output: $OUTPUT_DIR
EOF

# Run OPRO Classic
echo "============================================"
echo "STARTING OPRO CLASSIC OPTIMIZATION"
echo "============================================"
echo ""

python scripts/opro_classic_optimize.py \
    --manifest "$(pwd)/$MANIFEST" \
    --split "$SPLIT" \
    --output_dir "$OUTPUT_DIR" \
    $CHECKPOINT_ARG \
    --optimizer_llm "$OPTIMIZER_LLM" \
    --num_iterations $NUM_ITERATIONS \
    --candidates_per_iter $CANDIDATES_PER_ITER \
    --early_stopping $EARLY_STOPPING \
    --max_eval_samples $MAX_EVAL_SAMPLES \
    --sample_strategy "$SAMPLE_STRATEGY" \
    --per_condition_k $PER_CONDITION_K \
    --seed $SEED

EXIT_CODE=$?

echo ""
echo "============================================"
echo "OPRO CLASSIC COMPLETE"
echo "============================================"
echo "Exit code: $EXIT_CODE"
echo "End time: $(date)"
echo ""

if [ $EXIT_CODE -eq 0 ]; then
    echo "✓ SUCCESS"
    echo ""
    echo "Results saved to: $OUTPUT_DIR"
    echo ""

    if [ -f "$OUTPUT_DIR/best_prompt.txt" ]; then
        echo "Best prompt:"
        cat "$OUTPUT_DIR/best_prompt.txt"
        echo ""
    fi

    if [ -f "$OUTPUT_DIR/best_metrics.json" ]; then
        echo "Best metrics:"
        cat "$OUTPUT_DIR/best_metrics.json"
        echo ""
    fi
else
    echo "✗ FAILED with exit code $EXIT_CODE"
    echo "Check logs in: logs/opro_classic_${SLURM_JOB_ID}.err"
fi

echo "============================================"

exit $EXIT_CODE
